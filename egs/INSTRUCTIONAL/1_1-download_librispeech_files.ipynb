{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1: Download `librispeech` files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a free dataset consisting of readings from books available at `project gutenberg`.\n",
    "\n",
    "The language models and lexicons are explained [here](http://www.openslr.org/12/).\n",
    "\n",
    "Note: You do **not** need to download them yourself.  The scripts below will automatically download the necessary files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location to download raw audio\n",
    "data=${KALDI_INSTRUCTIONAL_PATH}/raw_data\n",
    "mkdir $data\n",
    "\n",
    "# base url for downloads\n",
    "data_url=www.openslr.org/resources/12\n",
    "lm_url=www.openslr.org/resources/11\n",
    "\n",
    "# source files with path information\n",
    ". ./path.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The audio files are explained [here](http://www.openslr.org/12/).  \n",
    "\n",
    "There are two sets of audio: `clean` and `other`.  `clean` is a subset of the audio that is very clearly articulated and \"easier\" to run through `ASR`.  `other` is a subset of data that is much more difficult to run through `ASR`.  There are also three different sized training sets: `100 hrs`, `360 hrs`, and `500 hrs`.  \n",
    "\n",
    "We will do all of our training on `train-clean-100`, and will test on *both* `test-clean` and `test-other`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![audio_splits](notebook_images/1_1-librispeech_audio_splits.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command below will download the following audio subsets into the directory `INSTRUCTIONAL/raw_data`:\n",
    " - `train-clean-100`\n",
    " - `dev-clean`\n",
    " - `dev-other`\n",
    " - `test-clean`\n",
    " - `test-other`\n",
    "\n",
    "**Note:** This step will likely take over `2 hr`s to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local/download_and_untar.sh: data part dev-clean was already successfully extracted, nothing to do.\n",
      "local/download_and_untar.sh: data part test-clean was already successfully extracted, nothing to do.\n",
      "local/download_and_untar.sh: data part dev-other was already successfully extracted, nothing to do.\n",
      "local/download_and_untar.sh: data part test-other was already successfully extracted, nothing to do.\n",
      "local/download_and_untar.sh: removing existing file /home//kaldi/egs/INSTRUCTIONAL/raw_data/train-clean-100.tar.gz because its size in bytes 1098901280\n",
      "does not equal the size of one of the archives.\n",
      "local/download_and_untar.sh: downloading data from www.openslr.org/resources/12/train-clean-100.tar.gz.  This may take some time, please be patient.\n",
      "--2017-10-19 22:04:54--  http://www.openslr.org/resources/12/train-clean-100.tar.gz\n",
      "Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n",
      "Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6387309499 (5.9G) [application/x-gzip]\n",
      "Saving to: 'train-clean-100.tar.gz'\n",
      "\n",
      "train-clean-100.tar   0%[                    ]   1.84M   587KB/s    eta 2h 56m \n"
     ]
    }
   ],
   "source": [
    "for part in dev-clean test-clean dev-other test-other train-clean-100; do\n",
    "  local/download_and_untar.sh $data $data_url $part\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading `language model`s and `lexicon`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the other files needed, `language model`s and `lexicon`, have already been created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![lm_files](notebook_images/1_1-librispeech_data_files.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`librispeech-lm-norm.txt.gz` is a compressed file of the `text` used to build the language models. <br>\n",
    "`librispeech-lexicon.txt` is a file that contains all the words in the `ASR` vocabulary and their pronunciations. <br>\n",
    "`3-gram.arpa.gz` is a compressed `3-gram` `language model`. <br>\n",
    "`3-gram.pruned.1e-7.arpa.gz` and `3gram.pruned.3e-7.arpa.gz` are `prune`d versions of `3-gram.arpa.gz`. <br>\n",
    "`4-gram.arpa.gz` is a `4-gram` `language model`. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command below will download these files into the directory `INSTRUCTIONAL/raw_data`.\n",
    "\n",
    "**Note:** This step will likely take about `1 hr` to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file '3-gram.arpa.gz' into '/home//kaldi/egs/INSTRUCTIONAL/raw_data'...\n",
      "WARNING: '3-gram.arpa.gz' exists, but the size is wrong - re-downloading ...\n",
      "--2017-10-19 22:05:00--  http://www.openslr.org/resources/11/3-gram.arpa.gz\n",
      "Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n",
      "Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 759636181 (724M) [application/x-gzip]\n",
      "Saving to: '/home//kaldi/egs/INSTRUCTIONAL/raw_data/3-gram.arpa.gz'\n",
      "\n",
      "RUCTIONAL/raw_data/  17%[==>                 ] 124.35M   809KB/s    eta 10m 51s\n"
     ]
    }
   ],
   "source": [
    "local/download_lm.sh $lm_url $data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
