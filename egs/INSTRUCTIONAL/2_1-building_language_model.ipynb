{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1: Building a language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`kaldi` has native support for the `ARPA` format for language models.  A good explanation of that format can be read [here](https://cmusphinx.github.io/wiki/arpaformat/), but here is the basic format:\n",
    "\n",
    "A popular open-source language modeling toolkit that outputs in the `ARPA` format is `IRSTLM`.  It's manual can be found in `resource_files/irstlm-manual.pdf`.\n",
    "\n",
    "We will build a language model from a toy corpus (using `IRSTLM`) and then analyze it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the toy corpus\n",
    "\n",
    "A toy corpus is in `resource_files/animal_corpus.txt`.  In this corpus, each line represents a sentence, and there is *no* punctuation present.\n",
    "\n",
    "**Note:** From the perspective of a language model, one *could* model punctuation if that were of importance, but since our purpose is to model *spoken* text, we do *not* have any need to model punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mouse ate the cheese\n",
      "the cat ate the mouse\n",
      "the dog ate the cat\n",
      "the lion at the dog\n",
      "the tyrannosaurus rex ate the lion\n",
      "the human shot the mouse\n",
      "the human shot the cat\n",
      "the human shot the dog\n",
      "the human shot the lion\n",
      "the human shot the tyrannosaurus rex\n"
     ]
    }
   ],
   "source": [
    "cat resource_files/animal_corpus.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building the language model with `IRSTLM`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After `export`ing a few variables, we will be able to call scripts from `IRSTLM` without a full path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "export IRSTLM=${KALDI_PATH}/tools/irstlm\n",
    "export PATH=${PATH}:${IRSTLM}/bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `add-start-end.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our corpus does *not* have periods, we need to add a custom symbol to represent the *beginning* and *end* of each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "add-start-end.sh - adds sentence start/end symbols in each line and trims very very long words\n",
      "\n",
      "USAGE:\n",
      "       add-start-end.sh [options]\n",
      "\n",
      "OPTIONS:\n",
      "       -h        Show this message\n",
      "       -r count  Specify symbol repetitions (default 1)\n",
      "       -t length Trim words up to _length_ chars (default 80)\n",
      "       -s char   Specify symbol (default s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "add-start-end.sh -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat resource_files/animal_corpus.txt | add-start-end.sh > resource_files/animal_corpus_start_stop.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> the mouse ate the cheese  </s>\n",
      "<s> the cat ate the mouse  </s>\n",
      "<s> the dog ate the cat  </s>\n",
      "<s> the lion at the dog  </s>\n",
      "<s> the tyrannosaurus rex ate the lion  </s>\n",
      "<s> the human shot the mouse  </s>\n",
      "<s> the human shot the cat  </s>\n",
      "<s> the human shot the dog  </s>\n",
      "<s> the human shot the lion  </s>\n",
      "<s> the human shot the tyrannosaurus rex  </s>\n"
     ]
    }
   ],
   "source": [
    "cat resource_files/animal_corpus_start_stop.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `build-lm.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build the actual language model using `build-lm.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "build-lm.sh - estimates a language model file and saves it in intermediate ARPA format\n",
      "\n",
      "USAGE:\n",
      "       build-lm.sh [options]\n",
      "\n",
      "OPTIONS:\n",
      "       -i|--InputFile          Input training file e.g. 'gunzip -c train.gz'\n",
      "       -o|--OutputFile         Output gzipped LM, e.g. lm.gz\n",
      "       -k|--Parts              Number of splits (default 5)\n",
      "       -n|--NgramSize          Order of language model (default 3)\n",
      "       -d|--Dictionary         Define subdictionary for n-grams (optional, default is without any subdictionary)\n",
      "       -s|--LanguageModelType  Smoothing methods: witten-bell (default), shift-beta, improved-shift-beta, stupid-backoff; kneser-ney and improved-kneser-ney still accepted for back-compatibility, but mapped into shift-beta and improved-shift-beta, respectively\n",
      "       -p|--PruneSingletons    Prune singleton n-grams (default false)\n",
      "       -f|--PruneFrequencyThreshold      Pruning frequency threshold for each level; comma-separated list of values; (default is '0,0,...,0', for all levels)\n",
      "       -t|--TmpDir             Directory for temporary files (default ./stat_PID)\n",
      "       -l|--LogFile            File to store logging info (default /dev/null)\n",
      "       -u|--uniform            Use uniform word frequency for dictionary splitting (default false)\n",
      "       -b|--boundaries         Include sentence boundary n-grams (optional, default false)\n",
      "       -v|--verbose            Verbose\n",
      "       --debug                 Debug\n",
      "       -h|-?|--help            Show this message\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build-lm.sh -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main arguments we will focus on are:\n",
    " - `-i`\n",
    " - `-o`\n",
    " - `-n`\n",
    "\n",
    "`-k` is an important argument for efficient language modeling on a very large corpus.  With our toy example, we do not need to worry about that.  You'll also notice a number of options for `-s` which relate to the type of `smoothing` used.  Stanford has a great resource on `smoothing` that you can find in `resource_files/smoothing_explained.pdf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGFILE:/dev/null\n",
      "$bin/ngt -i=\"$inpfile\" -n=$order -gooout=y -o=\"$gzip -c > $tmpdir/ngram.${sdict}.gz\" -fd=\"$tmpdir/$sdict\" $dictionary $additional_parameters >> $logfile 2>&1\n",
      "$scr/build-sublm.pl $verbose $prune $prune_thr_str $smoothing \"$additional_smoothing_parameters\" --size $order --ngrams \"$gunzip -c $tmpdir/ngram.${sdict}.gz\" -sublm $tmpdir/lm.$sdict $additional_parameters >> $logfile 2>&1\n"
     ]
    }
   ],
   "source": [
    "build-lm.sh \\\n",
    "    -i resource_files/lm_temp/animal_corpus_start_stop.txt \\\n",
    "    -o resource_files/animal_lm-2_gram.lm \\\n",
    "    -n 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`IRSTLM` automatically `compresses` the resulting language model.  So we will `decompress` it so we can look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gzip -d resource_files/animal_lm-2_gram.lm.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iARPA\n",
      "\n",
      "\\data\\\n",
      "ngram 1=\t15\n",
      "ngram 2=\t25\n",
      "\n",
      "\\1-grams:\n",
      "-1.662758\t<s>\t-0.845098\n",
      "-0.641569\tthe\t-0.586266\n",
      "-1.361728\tmouse\t-0.397940\n",
      "-1.264818\tate\t-0.698970\n",
      "-1.662758\tcheese\t-0.301030\n",
      "-0.922395\t</s>\t-1.041393\n",
      "-1.361728\tcat\t-0.397940\n",
      "-1.361728\tdog\t-0.397940\n",
      "-1.361728\tlion\t-0.397940\n",
      "-1.662758\tat\t-0.301030\n",
      "-1.486667\ttyrannosaurus\t-0.477121\n",
      "-1.486667\trex\t-0.301030\n",
      "-1.185637\thuman\t-0.778151\n",
      "-1.185637\tshot\t-0.778151\n",
      "-0.787697 <unk>\n",
      "\\2-grams:\n",
      "-0.845098\t<s> <s>\n",
      "-0.146128\t<s> the\n",
      "-0.954243\tthe mouse\n",
      "-1.431364\tthe cheese\n",
      "-0.954243\tthe cat\n",
      "-0.954243\tthe dog\n",
      "-0.954243\tthe lion\n",
      "-1.130334\tthe tyrannosaurus\n",
      "-0.732394\tthe human\n",
      "-0.698970\tmouse ate\n",
      "-0.397940\tmouse </s>\n",
      "-0.096910\tate the\n",
      "-0.301030\tcheese </s>\n",
      "-0.698970\tcat ate\n",
      "-0.397940\tcat </s>\n",
      "-0.698970\tdog ate\n",
      "-0.397940\tdog </s>\n",
      "-0.397940\tlion </s>\n",
      "-0.698970\tlion at\n",
      "-0.301030\tat the\n",
      "-0.176091\ttyrannosaurus rex\n",
      "-0.602060\trex ate\n",
      "-0.602060\trex </s>\n",
      "-0.079181\thuman shot\n",
      "-0.079181\tshot the\n",
      "\\end\\\n"
     ]
    }
   ],
   "source": [
    "cat resource_files/animal_lm-2_gram.lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `compile-lm`\n",
    "\n",
    "`compile-lm` can be used to put our language model into memory and evaluate in it in different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "compile-lm - compiles an ARPA format LM into an IRSTLM format one\n",
      "\n",
      "USAGE:\n",
      "       compile-lm [options] <input-file.lm> [output-file.blm]\n",
      "\n",
      "DESCRIPTION:\n",
      "       compile-lm reads a standard LM file in ARPA format and produces\n",
      "       a compiled representation that the IRST LM toolkit can quickly\n",
      "       read and process. LM file can be compressed.\n",
      "\n",
      "OPTIONS:\n",
      "Parameters:\n",
      "    Help:      print this help\n",
      "    d:      verbose output for --eval option; default is 0\n",
      "    debug:      verbose output for --eval option; default is 0\n",
      "    dict_load_factor:      sets the load factor for ngram cache; it should be a positive real value; default is 0\n",
      "    dub:      dictionary upperbound to compute OOV word penalty: default 10^7\n",
      "    e:      computes perplexity of the specified text file\n",
      "    eval:      computes perplexity of the specified text file\n",
      "    f:      filter a binary language model with a word list\n",
      "    filter:      filter a binary language model with a word list\n",
      "    h:      print this help\n",
      "    i:      builds an inverted n-gram binary table for fast access; default if false\n",
      "    invert:      builds an inverted n-gram binary table for fast access; default if false\n",
      "    keep-start-symbols:      keeps (or not) multiple contiguous start symbols in the n-grams; false means that just one start symbol is kept, true means that all start symbols are kept\n",
      "    keepunigrams:      filter by keeping all unigrams in the table, default  is true\n",
      "    ku:      filter by keeping all unigrams in the table, default  is true\n",
      "    l:      maximum level to load from the LM; if value is larger than the actual LM order, the latter is taken\n",
      "    level:      maximum level to load from the LM; if value is larger than the actual LM order, the latter is taken\n",
      "    memmap:      uses memory map to read a binary LM\n",
      "    mm:      uses memory map to read a binary LM\n",
      "    ngram_load_factor:      sets the load factor for ngram cache; it should be a positive real value; default is false\n",
      "    ngramscore:      computes log-prob scores of the last n-gram  before an _END_NGRAM_ symbol from standard input\n",
      "    ns:      computes log-prob scores of the last n-gram  before an _END_NGRAM_ symbol from standard input\n",
      "    r:      computes N random calls on the specified text file\n",
      "    randcalls:      computes N random calls on the specified text file\n",
      "    s:      computes log-prob scores of n-grams from standard input\n",
      "    score:      computes log-prob scores of n-grams from standard input\n",
      "    sentence:      computes perplexity at sentence level (identified through the end symbol)\n",
      "    t:      output is again in text format; default is false\n",
      "    text:      output is again in text format; default is false\n",
      "    tmpdir:      directory for temporary computation, default is either the environment variable TMP if defined or \"/tmp\")\n",
      "\n",
      "DEBUG_LEVEL:0/1 Everything OK\n"
     ]
    }
   ],
   "source": [
    "compile-lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have a second corpus that we will consider our \"test\" corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> the mouse ate the cat </s>\n",
      "<s> the tyrannosaurus shot the human </s>\n",
      "<s> the triceratops ate the lettuce </s>\n"
     ]
    }
   ],
   "source": [
    "cat resource_files/animal_test_corpus.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this test corpus already has the `start` and `stop` symbls added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `perplexity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inpfile: resource_files/animal_lm-2_gram.lm\n",
      "outfile: animal_lm-2_gram.lm.blm\n",
      "evalfile: yes\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "OOV code is 14\n",
      "OOV code is 14\n",
      "Start Eval\n",
      "OOV code: 14\n",
      "%% Nw=0 PP=-nan PPwp=-nan Nbo=0 Noov=0 OOV=-nan%\n"
     ]
    }
   ],
   "source": [
    "compile-lm resource_files/animal_lm-2_gram.lm --eval=yes < resource_files/animal_test_corpus.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `probability` of `n-gram`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inpfile: resource_files/animal_lm-2_gram.lm\n",
      "outfile: animal_lm-2_gram.lm.blm\n",
      "interactive: 1\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "OOV code is 14\n",
      "OOV code is 14\n",
      "> <s> the\t1 p= -0x1.2ad5dc53d7533p-2 bo= 0\n",
      "> the mouse\t1 p= -0x1.0ce06c02e8a4cp+1 bo= 0\n",
      "> mouse ate\t1 p= -0x1.8199d8c0e0c22p+0 bo= 0\n",
      "> ate the\t1 p= -0x1.57576708db605p-3 bo= 0\n",
      "> the cat\t1 p= -0x1.0ce06c02e8a4cp+1 bo= 0\n",
      "> cat </s>\t1 p= -0x1.9b50bb08ac0a2p-1 bo= 0\n",
      "> <s> the\t1 p= -0x1.2ad5dc53d7533p-2 bo= 0\n",
      "> the tyrannosaurus\t1 p= -0x1.3f4f94250d429p+1 bo= 0\n",
      "> tyrannosaurus shot\t1 p= -0x1.ea10eef56f1fep+1 bo= 1\n",
      "> shot the\t1 p= -0x1.19f81ab71a53dp-3 bo= 0\n",
      "> the human\t1 p= -0x1.9959c279b8b8ep+0 bo= 0\n",
      "> human </s>\t1 p= -0x1.f53413f41718ap+1 bo= 1\n",
      "> <s> the\t1 p= -0x1.2ad5dc53d7533p-2 bo= 0\n",
      "> the <unk>\t1 p= -0x1.348217af7430ap+4 bo= 1\n",
      "> <unk> ate\t1 p= -0x1.74c7ea98d13adp+1 bo= 1\n",
      "> ate the\t1 p= -0x1.57576708db605p-3 bo= 0\n",
      "> the <unk>\t1 p= -0x1.348217af7430ap+4 bo= 1\n",
      "> <unk> </s>\t1 p= -0x1.0fdbb970ffb3p+1 bo= 1\n",
      "> \n"
     ]
    }
   ],
   "source": [
    "compile-lm resource_files/animal_lm-2_gram.lm --score=yes < resource_files/animal_test_corpus.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inpfile: resource_files/animal_lm-2_gram.lm\n",
      "outfile: animal_lm-2_gram.lm.blm\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "OOV code is 14\n",
      "OOV code is 14\n",
      "Saving in bin format to animal_lm-2_gram.lm.blm\n"
     ]
    }
   ],
   "source": [
    "compile-lm resource_files/animal_lm-2_gram.lm --sentence=yes < resource_files/animal_test_corpus.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inpfile: resource_files/animal_lm-2_gram.lm\n",
      "outfile: animal_lm-2_gram.lm.blm\n",
      "interactive for ngrams only: 1\n",
      "loading up to the LM level 1000 (if any)\n",
      "dub: 10000000\n",
      "OOV code is 14\n",
      "OOV code is 14\n"
     ]
    }
   ],
   "source": [
    "echo \"the human ate the cheese\" | compile-lm resource_files/animal_lm-2_gram.lm --ngramscore=yes "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
