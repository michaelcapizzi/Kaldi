{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2: Examining language models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ARPA` (and `iARPA`) format is very interpretable.  If you haven't yet done so, read this short [blog post](https://cmusphinx.github.io/wiki/arpaformat/) for more information on how to interpret them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iARPA\n",
      "\n",
      "\\data\\\n",
      "ngram 1=\t15\n",
      "ngram 2=\t33\n",
      "\n",
      "\\1-grams:\n",
      "-1.826075\t<s>\t-0.698970\n",
      "-0.583037\tthe\t-0.767686\n",
      "-1.348954\tmouse\t-0.352183\n",
      "-0.951014\tate\t-1.176091\n",
      "-1.348954\tcheese\t-0.544068\n",
      "-1.282007\t</s>\t-0.845098\n",
      "-1.282007\tcat\t-0.397940\n",
      "-1.085712\tand\t-1.041393\n",
      "-1.282007\tdog\t-0.397940\n",
      "-1.282007\tlion\t-0.477121\n",
      "-1.348954\ttyrannosaurus\t-0.778151\n",
      "-1.348954\trex\t-0.544068\n",
      "-1.826075\thuman\t-0.301030\n",
      "-1.826075\tshot\t-0.301030\n",
      "-0.951014\t<unk>\n",
      "\\2-grams:\n",
      "-0.698970\t<s> <s>\n",
      "-0.221849\t<s> the\n",
      "-0.913814\tthe mouse\n",
      "-0.913814\tthe cheese\n",
      "-0.834633\tthe cat\n",
      "-0.834633\tthe dog\n",
      "-0.834633\tthe lion\n",
      "-0.913814\tthe tyrannosaurus\n",
      "-1.612784\tthe human\n",
      "-0.954243\tmouse the\n",
      "-0.954243\tmouse ate\n",
      "-0.954243\tmouse </s>\n",
      "-0.653213\tmouse and\n",
      "-0.029963\tate the\n",
      "-0.845098\tcheese </s>\n",
      "-0.243038\tcheese and\n",
      "-1.000000\tcat the\n",
      "-0.698970\tcat ate\n",
      "-1.000000\tcat </s>\n",
      "-0.698970\tcat and\n",
      "-0.041393\tand the\n",
      "-1.000000\tdog the\n",
      "-0.522879\tdog ate\n",
      "-1.000000\tdog </s>\n",
      "-1.000000\tdog and\n",
      "-0.352183\tlion ate\n",
      "-0.954243\tlion </s>\n",
      "-0.954243\tlion and\n",
      "-0.079181\ttyrannosaurus rex\n",
      "-0.243038\trex ate\n",
      "-0.845098\trex </s>\n",
      "-0.301030\thuman shot\n",
      "-0.301030\tshot the\n",
      "\\end\\\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat resource_files/language_model/animal_lm-2_gram.iarpa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `PyNLPl`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the [`PyNLPl`](http://pynlpl.readthedocs.io/en/latest/) (pronounced \"pineapple\") package in `python` to examine our language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynlpl.lm.lm as lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading in `.iARPA` files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ARPALanguageModel()` will import an existing **`iARPA`** formatted language model.\n",
    "\n",
    "**Note:** Recall that in the last notebook we had to run a quick `sed` command over the `.iarpa` format because there were times where the whitespace between a probability and the unigram was a `\" \"` instead of a `\\t`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to parse ARPA LM line: iARPA\n",
      "Adding to LM: (u'<s>',)\t-1.826075\t-0.69897\n",
      "Adding to LM: (u'the',)\t-0.583037\t-0.767686\n",
      "Adding to LM: (u'mouse',)\t-1.348954\t-0.352183\n",
      "Adding to LM: (u'ate',)\t-0.951014\t-1.176091\n",
      "Adding to LM: (u'cheese',)\t-1.348954\t-0.544068\n",
      "Adding to LM: (u'</s>',)\t-1.282007\t-0.845098\n",
      "Adding to LM: (u'cat',)\t-1.282007\t-0.39794\n",
      "Adding to LM: (u'and',)\t-1.085712\t-1.041393\n",
      "Adding to LM: (u'dog',)\t-1.282007\t-0.39794\n",
      "Adding to LM: (u'lion',)\t-1.282007\t-0.477121\n",
      "Adding to LM: (u'tyrannosaurus',)\t-1.348954\t-0.778151\n",
      "Adding to LM: (u'rex',)\t-1.348954\t-0.544068\n",
      "Adding to LM: (u'human',)\t-1.826075\t-0.30103\n",
      "Adding to LM: (u'shot',)\t-1.826075\t-0.30103\n",
      "Adding to LM: (u'<unk>',)\t-0.951014\n",
      "Adding to LM: (u'<s>', u'<s>')\t-0.69897\n",
      "Adding to LM: (u'<s>', u'the')\t-0.221849\n",
      "Adding to LM: (u'the', u'mouse')\t-0.913814\n",
      "Adding to LM: (u'the', u'cheese')\t-0.913814\n",
      "Adding to LM: (u'the', u'cat')\t-0.834633\n",
      "Adding to LM: (u'the', u'dog')\t-0.834633\n",
      "Adding to LM: (u'the', u'lion')\t-0.834633\n",
      "Adding to LM: (u'the', u'tyrannosaurus')\t-0.913814\n",
      "Adding to LM: (u'the', u'human')\t-1.612784\n",
      "Adding to LM: (u'mouse', u'the')\t-0.954243\n",
      "Adding to LM: (u'mouse', u'ate')\t-0.954243\n",
      "Adding to LM: (u'mouse', u'</s>')\t-0.954243\n",
      "Adding to LM: (u'mouse', u'and')\t-0.653213\n",
      "Adding to LM: (u'ate', u'the')\t-0.029963\n",
      "Adding to LM: (u'cheese', u'</s>')\t-0.845098\n",
      "Adding to LM: (u'cheese', u'and')\t-0.243038\n",
      "Adding to LM: (u'cat', u'the')\t-1.0\n",
      "Adding to LM: (u'cat', u'ate')\t-0.69897\n",
      "Adding to LM: (u'cat', u'</s>')\t-1.0\n",
      "Adding to LM: (u'cat', u'and')\t-0.69897\n",
      "Adding to LM: (u'and', u'the')\t-0.041393\n",
      "Adding to LM: (u'dog', u'the')\t-1.0\n",
      "Adding to LM: (u'dog', u'ate')\t-0.522879\n",
      "Adding to LM: (u'dog', u'</s>')\t-1.0\n",
      "Adding to LM: (u'dog', u'and')\t-1.0\n",
      "Adding to LM: (u'lion', u'ate')\t-0.352183\n",
      "Adding to LM: (u'lion', u'</s>')\t-0.954243\n",
      "Adding to LM: (u'lion', u'and')\t-0.954243\n",
      "Adding to LM: (u'tyrannosaurus', u'rex')\t-0.079181\n",
      "Adding to LM: (u'rex', u'ate')\t-0.243038\n",
      "Adding to LM: (u'rex', u'</s>')\t-0.845098\n",
      "Adding to LM: (u'human', u'shot')\t-0.30103\n",
      "Adding to LM: (u'shot', u'the')\t-0.30103\n"
     ]
    }
   ],
   "source": [
    "bi_gram_lm = lm.ARPALanguageModel(\n",
    "    filename=\"resource_files/language_model/animal_lm-2_gram.iarpa\",\n",
    "    base_e=False,  # this will keep the log probabilities in `base 10` so that they match up with the original file\n",
    "    debug=True     # this argument will allow you to more easily see how the data is stored in the object\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that each `n-gram` is stored as a `<tuple>`, even `unigram`s ==> `([word],)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### looking up **existing** `n-gram`s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.ngrams` contains all the of `n-gram`s **present** in our language model.  We can access either:\n",
    " - the probability ==> `.prob()`\n",
    " - the backoff probability ==> `.backoff()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.282007, -0.39794)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_gram_lm.ngrams.prob((\"dog\",)), bi_gram_lm.ngrams.backoff((\"dog\",))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm this by double-checking the values in the original `.iarpa` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.282007\tdog\t-0.397940\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat resource_files/language_model/animal_lm-2_gram.iarpa | grep -P \"\\tdog\\t\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.834633, 0.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_gram_lm.ngrams.prob((\"the\", \"dog\")), bi_gram_lm.ngrams.backoff((\"the\", \"dog\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.834633\tthe dog\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat resource_files/language_model/animal_lm-2_gram.iarpa | grep -P \"the dog\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we try to lookup an `n-gram` that does **not** exist in the language model explicitly, we get a `KeyError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-gram ('the', 'dog', 'ate') doesn't exist in language model\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    bi_gram_lm.ngrams.prob((\"the\", \"dog\", \"ate\"))\n",
    "except Exception as e:\n",
    "    print(\"n-gram {} doesn't exist in language model\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-gram ('human', 'ate') doesn't exist in language model\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    bi_gram_lm.ngrams.prob((\"human\", \"ate\"))\n",
    "except Exception as e:\n",
    "    print(\"n-gram {} doesn't exist in language model\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculating new `n-gram` probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these cases, we can use `.score()`.  To score a new `n-gram`, provide that `n-gram` as a `<tuple>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.9405489999999999"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_gram_lm.score((\"the\", \"dog\", \"ate\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you forget to submit the `n-gram` as a `<tuple>`, the `<string>` will be considered an `n-gram` of **characters**, **none of which** will be present in the language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.461154"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_gram_lm.score(\"the dog ate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.461154"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = 0\n",
    "for i in \"the dog ate\":\n",
    "    result += bi_gram_lm.scoreword(i)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you try to calculate the score of \"the dog\" by entering it as a `<string>` to the first argument, you will get the score of the `unigram`, `<unk>`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.951014"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_gram_lm.scoreword(\"the dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.951014\t<unk>\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat resource_files/language_model/animal_lm-2_gram.iarpa | grep \"<unk>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.002166, -0.951014, -3.002166)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_gram_lm.scoreword((\"human\",), (\"ate\",)), bi_gram_lm.scoreword((\"human\", \"ate\")), bi_gram_lm.score((\"human\",), (\"ate\",))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are using a `2-gram` language model, there is no entry for a `3-gram`, but`PyNLPl` will do the calculations of that for us.\n",
    "\n",
    "$p(the\\_dog\\_ate) = p(dog|the) + p(ate|dog)$  \n",
    "\n",
    "**Note:** Remember because we are in `log` space, we `add` instead of `multiply`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.3575119999999998"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_gram_lm.scoreword((\"dog\",), (\"the\",)) + bi_gram_lm.scoreword((\"ate\",), (\"dog\",))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But instead of doing the addition ourselves, we can use the `score()` method.  It again takes two arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.3575119999999998, -0.522879)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_gram_lm.score((\"dog\", \"ate\"), (\"the\",)), bi_gram_lm.scoreword((\"dog\", \"ate\"), (\"the\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.834633"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_gram_lm.scoreword((\"the\", \"dog\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
