{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: This `notebook` is built for a `python` kernel, and so the default setting for each cell is `python`.  But you can use `%%bash` at the beginning of any cell to utilize `shell`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import utils.feature_viz.feature_viz as fv\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3: Examining the `MFCC`s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `INSTRUCTIONAL` directory has a copy of [this third-party repository](https://github.com/vesis84/kaldi-io-for-python) in `utils/feature_viz`.  `utils/feature_viz/kaldi_io.py` has methods that allow us to read from (and write to...though we won't be using that) `.ark` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.pyc\n",
      "kaldi_io.pyc\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls utils/feature_viz/kaldi_io_for_python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there is a `python` module called `feature_viz.py` that has some methods wrapping `kaldi_io.py` that we'll use below to examine the `MFCC` features we extracted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing an audio sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of our `mfcc` features are located in the `mfcc` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_mfcc_test_dir.1.ark\n",
      "raw_mfcc_test_dir.1.scp\n",
      "raw_mfcc_test_dir.2.ark\n",
      "raw_mfcc_test_dir.2.scp\n",
      "raw_mfcc_test_dir.3.ark\n",
      "raw_mfcc_test_dir.3.scp\n",
      "raw_mfcc_test_dir.4.ark\n",
      "raw_mfcc_test_dir.4.scp\n",
      "raw_mfcc_train_dir.1.ark\n",
      "raw_mfcc_train_dir.1.scp\n",
      "raw_mfcc_train_dir.2.ark\n",
      "raw_mfcc_train_dir.2.scp\n",
      "raw_mfcc_train_dir.3.ark\n",
      "raw_mfcc_train_dir.3.scp\n",
      "raw_mfcc_train_dir.4.ark\n",
      "raw_mfcc_train_dir.4.scp\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls mfcc | grep mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice a number of files equal to the parallelization that we utilized during feature extraction, and for each `int`, there will be an `.ark` and a `.scp` file.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If there is a *particular* audio sample that you'd like to inspect, you'll have to find which `.ark` file it resides in.\n",
    "\n",
    "For this example, we'll look at an example with some interesting sounds in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1272-128104-0000 MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL\n",
      "1272-128104-0001 NOR IS MISTER QUILTER'S MANNER LESS INTERESTING THAN HIS MATTER\n",
      "1272-128104-0002 HE TELLS US THAT AT THIS FESTIVE SEASON OF THE YEAR WITH CHRISTMAS AND ROAST BEEF LOOMING BEFORE US SIMILES DRAWN FROM EATING AND ITS RESULTS OCCUR MOST READILY TO THE MIND\n",
      "1272-128104-0003 HE HAS GRAVE DOUBTS WHETHER SIR FREDERICK LEIGHTON'S WORK IS REALLY GREEK AFTER ALL AND CAN DISCOVER IN IT BUT LITTLE OF ROCKY ITHACA\n",
      "1272-128104-0004 LINNELL'S PICTURES ARE A SORT OF UP GUARDS AND AT EM PAINTINGS AND MASON'S EXQUISITE IDYLLS ARE AS NATIONAL AS A JINGO POEM MISTER BIRKET FOSTER'S LANDSCAPES SMILE AT ONE MUCH IN THE SAME WAY THAT MISTER CARKER USED TO FLASH HIS TEETH AND MISTER JOHN COLLIER GIVES HIS SITTER A CHEERFUL SLAP ON THE BACK BEFORE HE SAYS LIKE A SHAMPOOER IN A TURKISH BATH NEXT MAN\n",
      "1272-128104-0005 IT IS OBVIOUSLY UNNECESSARY FOR US TO POINT OUT HOW LUMINOUS THESE CRITICISMS ARE HOW DELICATE IN EXPRESSION\n",
      "1272-128104-0006 ON THE GENERAL PRINCIPLES OF ART MISTER QUILTER WRITES WITH EQUAL LUCIDITY\n",
      "1272-128104-0007 PAINTING HE TELLS US IS OF A DIFFERENT QUALITY TO MATHEMATICS AND FINISH IN ART IS ADDING MORE FACT\n",
      "1272-128104-0008 AS FOR ETCHINGS THEY ARE OF TWO KINDS BRITISH AND FOREIGN\n",
      "1272-128104-0009 HE LAMENTS MOST BITTERLY THE DIVORCE THAT HAS BEEN MADE BETWEEN DECORATIVE ART AND WHAT WE USUALLY CALL PICTURES MAKES THE CUSTOMARY APPEAL TO THE LAST JUDGMENT AND REMINDS US THAT IN THE GREAT DAYS OF ART MICHAEL ANGELO WAS THE FURNISHING UPHOLSTERER\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head raw_data/librispeech-transcripts.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's find which `.ark` it is in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found in mfcc/raw_mfcc_test_dir.1.scp\n",
      "not found in mfcc/raw_mfcc_test_dir.2.scp\n",
      "not found in mfcc/raw_mfcc_test_dir.3.scp\n",
      "not found in mfcc/raw_mfcc_test_dir.4.scp\n",
      "found in mfcc/raw_mfcc_train_dir.1.scp: 1272-128104-0000 /home//kaldi/egs/INSTRUCTIONAL/mfcc/raw_mfcc_train_dir.1.ark:17\n",
      "not found in mfcc/raw_mfcc_train_dir.2.scp\n",
      "not found in mfcc/raw_mfcc_train_dir.3.scp\n",
      "not found in mfcc/raw_mfcc_train_dir.4.scp\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "for f in `ls mfcc/raw_mfcc_*.scp`; do\n",
    "    match=$(cat $f | grep \"1272-128104-0000\")\n",
    "    if [[ -z $match ]]; then\n",
    "        echo \"not found in $f\"\n",
    "    else\n",
    "        echo \"found in $f: $match\"\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE = \"1272-128104-0000\"\n",
    "ARK_SAMPLE = \"raw_mfcc_train_dir.1.scp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`read_in_features()` will read in the features for *all* of the utterances found in our `.ark`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2035-147961-0031',\n",
       " '2035-147961-0030',\n",
       " '2035-147961-0033',\n",
       " '2035-147961-0032',\n",
       " '2035-147961-0035',\n",
       " '2035-147961-0034',\n",
       " '2035-147961-0037',\n",
       " '2035-147960-0014',\n",
       " '2035-147961-0039',\n",
       " '2035-147961-0038']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_in = fv.read_in_features(\"mfcc/{}\".format(ARK_SAMPLE))\n",
    "list(feats_in.keys())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look more closely at our sample, the `value` is a `numpy array` representing the features for each frame in the utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 12.14908981, -21.18790054, -20.31894112, ...,  16.23352814,\n",
       "          0.05224136, -16.93466187],\n",
       "       [ 12.14908981, -21.75504494, -22.66297722, ...,  22.01498985,\n",
       "         -9.08587933,  -1.47463059],\n",
       "       [ 12.23464489, -19.48646164, -17.97490501, ...,  22.78585243,\n",
       "         -0.42246622,  -2.26634622],\n",
       "       ..., \n",
       "       [ 11.72131634, -24.59077454,  -8.06653976, ...,  11.60835743,\n",
       "         -1.01585066,  -2.7061882 ],\n",
       "       [ 11.63576221, -24.59077454,  -8.06653976, ...,  21.24412918,\n",
       "         -9.67926407,  -7.3891058 ],\n",
       "       [ 11.89242554, -22.32219124,  -6.91603661, ...,  16.23352814,\n",
       "         -7.06837225,  -5.78508282]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_in[SAMPLE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the feature shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of this `array` is `(num_frames x num_features)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(584, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_in[SAMPLE].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two functions in `feature_viz.py` that can also easily extract this information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(584, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fv.get_num_frames(feats_in[SAMPLE]), fv.get_num_features(feats_in[SAMPLE])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look back at the `MFCC` configuration file we used to extract these features, we'll see where this shape comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--frame-length=25               # frame length in milliseconds\n",
      "--frame-shift=10                # frame shift in milliseconds\n",
      "--num-ceps=13                   # number of cepstra in computation (incl. C0)\n",
      "--num-mel-bins=23               # number of triangular mel-frequency bins\n",
      "--use-energy=true               # use energy (not C0) in computation\n",
      "--low-freq=20                   # low cutoff frequency for mel bins\n",
      "--high-freq=0                   # high cutoff frequency for mel bins\n",
      "--window-type=povey             # choose \"hamming\", \"hanning\", \"rectangular\"\n",
      "--snip-edges=true               # only output frames that fit in file\n",
      "                                # number of frames depends on frame-length\n",
      "                                        # if false, depends on frame-shift\n",
      "--dither=1                      # random 1bit of noise added\n",
      "                                        # ensures no log(0) calculations\n",
      "--sample-frequency=8000         # sample rate of audio\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat conf/mfcc_defaults.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`--num-ceps` dictates the number of columns our features will have.\n",
    "\n",
    "And the number of frames depends on `--frame-length` and `--frame-shift` (along with the actual length of the audio of course).  In this case, each `frame` represents `25 ms` of audio, and the \"next frame\" is shifted `10 ms` to the right, and then consists of the next `25 ms`.  So our functions are overlapped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since \"1272-128104-0003\" is a significantly longer transcript, we can assume that it will have more features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1272-128104-0000 MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL\r\n",
      "1272-128104-0003 HE HAS GRAVE DOUBTS WHETHER SIR FREDERICK LEIGHTON'S WORK IS REALLY GREEK AFTER ALL AND CAN DISCOVER IN IT BUT LITTLE OF ROCKY ITHACA\r\n"
     ]
    }
   ],
   "source": [
    "cat raw_data/librispeech-transcripts.txt | grep -E \"1272-128104-000[03]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "988"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fv.get_num_frames(feats_in[\"1272-128104-0003\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, it will have the same number of `features`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fv.get_num_features(feats_in[\"1272-128104-0003\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`feature_viz.py` has a method `plot_frames()` that will plot the `MFCC`s for `n` consecutive frames of an audio sample\n",
    "\n",
    "**Note:** In order to view the plot directly in this notebook, you need run `py.iplot([output])` where `output` is the returned value from `plot_frames()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "lines",
         "name": "frame 1/1",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13
         ],
         "y": [
          21.19275665283203,
          8.513047218322754,
          12.229915618896484,
          14.741026878356934,
          -36.976112365722656,
          -7.1012115478515625,
          6.996381759643555,
          14.69707202911377,
          3.2988481521606445,
          11.841123580932617,
          -1.192874789237976,
          0.5269489288330078,
          -18.843772888183594
         ]
        }
       ],
       "layout": {
        "title": "Visualization of 1 frames",
        "xaxis": {
         "dtick": true,
         "title": "feature number"
        },
        "yaxis": {
         "title": "what does the value of y mean?"
        }
       }
      },
      "text/html": [
       "<div id=\"713db860-c38b-4e0b-8429-2597db0c595f\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"713db860-c38b-4e0b-8429-2597db0c595f\", [{\"y\": [21.19275665283203, 8.513047218322754, 12.229915618896484, 14.741026878356934, -36.976112365722656, -7.1012115478515625, 6.996381759643555, 14.69707202911377, 3.2988481521606445, 11.841123580932617, -1.192874789237976, 0.5269489288330078, -18.843772888183594], \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], \"type\": \"scatter\", \"name\": \"frame 1/1\", \"mode\": \"lines\"}], {\"title\": \"Visualization of 1 frames\", \"xaxis\": {\"dtick\": true, \"title\": \"feature number\"}, \"yaxis\": {\"title\": \"what does the value of y mean?\"}}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"713db860-c38b-4e0b-8429-2597db0c595f\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"713db860-c38b-4e0b-8429-2597db0c595f\", [{\"y\": [21.19275665283203, 8.513047218322754, 12.229915618896484, 14.741026878356934, -36.976112365722656, -7.1012115478515625, 6.996381759643555, 14.69707202911377, 3.2988481521606445, 11.841123580932617, -1.192874789237976, 0.5269489288330078, -18.843772888183594], \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], \"type\": \"scatter\", \"name\": \"frame 1/1\", \"mode\": \"lines\"}], {\"title\": \"Visualization of 1 frames\", \"xaxis\": {\"dtick\": true, \"title\": \"feature number\"}, \"yaxis\": {\"title\": \"what does the value of y mean?\"}}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the one *required* argument is a numpy array of features for any number of frames\n",
    "py.iplot(\n",
    "    fv.plot_frames(\n",
    "        frames=feats_in[SAMPLE][60:61]   # [x:y] will return the x^th frame\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see the first frame of features for our audio sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`plot_frames()` can also plot multiple **consecutive** frames on the same graph.  Below are five consecutive frames of audio.\n",
    "\n",
    "**Note:** `plotly` allows you to click \"on\" and \"off\" any particular line by clicking on them in the legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "lines",
         "name": "frame 1/8",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13
         ],
         "y": [
          21.19275665283203,
          8.513047218322754,
          12.229915618896484,
          14.741026878356934,
          -36.976112365722656,
          -7.1012115478515625,
          6.996381759643555,
          14.69707202911377,
          3.2988481521606445,
          11.841123580932617,
          -1.192874789237976,
          0.5269489288330078,
          -18.843772888183594
         ]
        },
        {
         "mode": "lines",
         "name": "frame 2/8",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13
         ],
         "y": [
          21.19275665283203,
          2.8768410682678223,
          21.759248733520508,
          9.17135238647461,
          -34.885494232177734,
          -0.9857975840568542,
          5.658081531524658,
          6.127485275268555,
          6.263431072235107,
          12.310379981994629,
          13.53551197052002,
          -13.002217292785645,
          -22.025625228881836
         ]
        },
        {
         "mode": "lines",
         "name": "frame 3/8",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13
         ],
         "y": [
          20.912734985351562,
          -4.710360050201416,
          28.112136840820312,
          9.867561340332031,
          -27.56831932067871,
          -3.3378798961639404,
          2.535382032394409,
          1.1862353086471558,
          16.644569396972656,
          9.96410083770752,
          28.95274543762207,
          -23.62842559814453,
          -10.57095718383789
         ]
        },
        {
         "mode": "lines",
         "name": "frame 4/8",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13
         ],
         "y": [
          20.38762092590332,
          -14.949294090270996,
          32.08269500732422,
          6.087552547454834,
          -20.7738037109375,
          8.10892105102539,
          -1.6282174587249756,
          20.570714950561523,
          5.320154666900635,
          15.125913619995117,
          17.0043888092041,
          -22.632343292236328,
          18.46919059753418
         ]
        },
        {
         "mode": "lines",
         "name": "frame 5/8",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13
         ],
         "y": [
          19.579753875732422,
          -26.859359741210938,
          24.141582489013672,
          18.570178985595703,
          8.147351264953613,
          12.051640510559082,
          13.521435737609863,
          3.7745091915130615,
          -8.41170883178711,
          0.9877848625183105,
          12.379219055175781,
          -20.142139434814453,
          4.8245391845703125
         ]
        },
        {
         "mode": "lines",
         "name": "frame 6/8",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13
         ],
         "y": [
          17.72165870666504,
          -26.292213439941406,
          16.200471878051758,
          6.699398040771484,
          5.803767204284668,
          -9.13968276977539,
          20.192459106445312,
          -8.354581832885742,
          1.681802749633789,
          -6.552258014678955,
          11.993788719177246,
          -3.9827730655670166,
          7.997714042663574
         ]
        },
        {
         "mode": "lines",
         "name": "frame 7/8",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13
         ],
         "y": [
          15.143502235412598,
          -14.949294090270996,
          20.965137481689453,
          3.2322745323181152,
          -2.491630792617798,
          -11.320476531982422,
          10.853026390075684,
          -5.840985298156738,
          2.490325450897217,
          -4.472246170043945,
          6.5723042488098145,
          -13.120893478393555,
          1.780200481414795
         ]
        },
        {
         "mode": "lines",
         "name": "frame 8/8",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13
         ],
         "y": [
          13.517964363098145,
          -8.829126358032227,
          10.641693115234375,
          -5.945405006408691,
          -4.847557067871094,
          3.4047560691833496,
          12.187231063842773,
          -4.332827568054199,
          17.90397071838379,
          -6.552258014678955,
          11.993788719177246,
          -15.659773826599121,
          4.507221221923828
         ]
        }
       ],
       "layout": {
        "title": "Visualization of 8 frames",
        "xaxis": {
         "dtick": true,
         "title": "feature number"
        },
        "yaxis": {
         "title": "what does the value of y mean?"
        }
       }
      },
      "text/html": [
       "<div id=\"1b514df9-f4c8-49a4-ac72-3285f9fea3d2\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"1b514df9-f4c8-49a4-ac72-3285f9fea3d2\", [{\"y\": [21.19275665283203, 8.513047218322754, 12.229915618896484, 14.741026878356934, -36.976112365722656, -7.1012115478515625, 6.996381759643555, 14.69707202911377, 3.2988481521606445, 11.841123580932617, -1.192874789237976, 0.5269489288330078, -18.843772888183594], \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], \"type\": \"scatter\", \"name\": \"frame 1/8\", \"mode\": \"lines\"}, {\"y\": [21.19275665283203, 2.8768410682678223, 21.759248733520508, 9.17135238647461, -34.885494232177734, -0.9857975840568542, 5.658081531524658, 6.127485275268555, 6.263431072235107, 12.310379981994629, 13.53551197052002, -13.002217292785645, -22.025625228881836], \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], \"type\": \"scatter\", \"name\": \"frame 2/8\", \"mode\": \"lines\"}, {\"y\": [20.912734985351562, -4.710360050201416, 28.112136840820312, 9.867561340332031, -27.56831932067871, -3.3378798961639404, 2.535382032394409, 1.1862353086471558, 16.644569396972656, 9.96410083770752, 28.95274543762207, -23.62842559814453, -10.57095718383789], \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], \"type\": \"scatter\", \"name\": \"frame 3/8\", \"mode\": \"lines\"}, {\"y\": [20.38762092590332, -14.949294090270996, 32.08269500732422, 6.087552547454834, -20.7738037109375, 8.10892105102539, -1.6282174587249756, 20.570714950561523, 5.320154666900635, 15.125913619995117, 17.0043888092041, -22.632343292236328, 18.46919059753418], \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], \"type\": \"scatter\", \"name\": \"frame 4/8\", \"mode\": \"lines\"}, {\"y\": [19.579753875732422, -26.859359741210938, 24.141582489013672, 18.570178985595703, 8.147351264953613, 12.051640510559082, 13.521435737609863, 3.7745091915130615, -8.41170883178711, 0.9877848625183105, 12.379219055175781, -20.142139434814453, 4.8245391845703125], \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], \"type\": \"scatter\", \"name\": \"frame 5/8\", \"mode\": \"lines\"}, {\"y\": [17.72165870666504, -26.292213439941406, 16.200471878051758, 6.699398040771484, 5.803767204284668, -9.13968276977539, 20.192459106445312, -8.354581832885742, 1.681802749633789, -6.552258014678955, 11.993788719177246, -3.9827730655670166, 7.997714042663574], \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], \"type\": \"scatter\", \"name\": \"frame 6/8\", \"mode\": \"lines\"}, {\"y\": [15.143502235412598, -14.949294090270996, 20.965137481689453, 3.2322745323181152, -2.491630792617798, -11.320476531982422, 10.853026390075684, -5.840985298156738, 2.490325450897217, -4.472246170043945, 6.5723042488098145, -13.120893478393555, 1.780200481414795], \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], \"type\": \"scatter\", \"name\": \"frame 7/8\", \"mode\": \"lines\"}, {\"y\": [13.517964363098145, -8.829126358032227, 10.641693115234375, -5.945405006408691, -4.847557067871094, 3.4047560691833496, 12.187231063842773, -4.332827568054199, 17.90397071838379, -6.552258014678955, 11.993788719177246, -15.659773826599121, 4.507221221923828], \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], \"type\": \"scatter\", \"name\": \"frame 8/8\", \"mode\": \"lines\"}], {\"title\": \"Visualization of 8 frames\", \"xaxis\": {\"dtick\": true, \"title\": \"feature number\"}, \"yaxis\": {\"title\": \"what does the value of y mean?\"}}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"1b514df9-f4c8-49a4-ac72-3285f9fea3d2\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"1b514df9-f4c8-49a4-ac72-3285f9fea3d2\", [{\"y\": [21.19275665283203, 8.513047218322754, 12.229915618896484, 14.741026878356934, -36.976112365722656, -7.1012115478515625, 6.996381759643555, 14.69707202911377, 3.2988481521606445, 11.841123580932617, -1.192874789237976, 0.5269489288330078, -18.843772888183594], \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], \"type\": \"scatter\", \"name\": \"frame 1/8\", \"mode\": \"lines\"}, {\"y\": [21.19275665283203, 2.8768410682678223, 21.759248733520508, 9.17135238647461, -34.885494232177734, -0.9857975840568542, 5.658081531524658, 6.127485275268555, 6.263431072235107, 12.310379981994629, 13.53551197052002, -13.002217292785645, -22.025625228881836], \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], \"type\": \"scatter\", \"name\": \"frame 2/8\", \"mode\": \"lines\"}, {\"y\": [20.912734985351562, -4.710360050201416, 28.112136840820312, 9.867561340332031, -27.56831932067871, -3.3378798961639404, 2.535382032394409, 1.1862353086471558, 16.644569396972656, 9.96410083770752, 28.95274543762207, -23.62842559814453, -10.57095718383789], \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], \"type\": \"scatter\", \"name\": \"frame 3/8\", \"mode\": \"lines\"}, {\"y\": [20.38762092590332, -14.949294090270996, 32.08269500732422, 6.087552547454834, -20.7738037109375, 8.10892105102539, -1.6282174587249756, 20.570714950561523, 5.320154666900635, 15.125913619995117, 17.0043888092041, -22.632343292236328, 18.46919059753418], \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], \"type\": \"scatter\", \"name\": \"frame 4/8\", \"mode\": \"lines\"}, {\"y\": [19.579753875732422, -26.859359741210938, 24.141582489013672, 18.570178985595703, 8.147351264953613, 12.051640510559082, 13.521435737609863, 3.7745091915130615, -8.41170883178711, 0.9877848625183105, 12.379219055175781, -20.142139434814453, 4.8245391845703125], \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], \"type\": \"scatter\", \"name\": \"frame 5/8\", \"mode\": \"lines\"}, {\"y\": [17.72165870666504, -26.292213439941406, 16.200471878051758, 6.699398040771484, 5.803767204284668, -9.13968276977539, 20.192459106445312, -8.354581832885742, 1.681802749633789, -6.552258014678955, 11.993788719177246, -3.9827730655670166, 7.997714042663574], \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], \"type\": \"scatter\", \"name\": \"frame 6/8\", \"mode\": \"lines\"}, {\"y\": [15.143502235412598, -14.949294090270996, 20.965137481689453, 3.2322745323181152, -2.491630792617798, -11.320476531982422, 10.853026390075684, -5.840985298156738, 2.490325450897217, -4.472246170043945, 6.5723042488098145, -13.120893478393555, 1.780200481414795], \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], \"type\": \"scatter\", \"name\": \"frame 7/8\", \"mode\": \"lines\"}, {\"y\": [13.517964363098145, -8.829126358032227, 10.641693115234375, -5.945405006408691, -4.847557067871094, 3.4047560691833496, 12.187231063842773, -4.332827568054199, 17.90397071838379, -6.552258014678955, 11.993788719177246, -15.659773826599121, 4.507221221923828], \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], \"type\": \"scatter\", \"name\": \"frame 8/8\", \"mode\": \"lines\"}], {\"title\": \"Visualization of 8 frames\", \"xaxis\": {\"dtick\": true, \"title\": \"feature number\"}, \"yaxis\": {\"title\": \"what does the value of y mean?\"}}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "py.iplot(\n",
    "    fv.plot_frames(\n",
    "        frames=feats_in[SAMPLE][60:68]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including `phone` information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If provided with the information, `plot_frames()` can also label each `frame` by its *predicted* phone.  It is a *predicted* phone because the **alignment*** of frames to a transcript is an integral part of the ASR pipeline, but its accuracy is dependent on the quality of the pipeline.\n",
    "\n",
    "In our case, we have **not yet** done the steps in the pipeline that generate these `alignment` files (typically called `ali.*.gz`).   But for the sake of these visualizations, the alignments we need are included in `resource_files/feature_viz/all_ali`.  This is an `un-compressed` (`gzip -d`), concatenated (of all of the parallelized outputs) file that contains alignmenet information for all of the audio in our training subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_ali\n",
      "all_ali_phoned\n",
      "model_for_alignments.mdl\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls resource_files/feature_viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a `C++` function called `ali-to-phones` to inspect these alignments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# we need to source path.sh which allows us to provide just the function name instead of full paths\n",
    ". path.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env bash\n",
      "\n",
      "# adds root directory of `kaldi` to $PATH\n",
      "export KALDI_ROOT=`pwd`/../../\n",
      "\n",
      "# adds librispeech_instructional/utils to $PATH\n",
      "# adds openfst to $PATH\n",
      "# adds IRSTLM to $PATH\n",
      "export PATH=$PWD/utils/:$KALDI_ROOT/tools/openfst/bin:$PWD:$PATH\n",
      "\n",
      "[ ! -f $KALDI_ROOT/tools/config/common_path.sh ] && echo >&2 \"The standard file $KALDI_ROOT/tools/config/common_path.sh is not present -> Exit!\" && exit 1\n",
      ". $KALDI_ROOT/tools/config/common_path.sh\n",
      "export LC_ALL=C\n",
      "\n",
      "# we use this both in the (optional) LM training and the G2P-related scripts\n",
      "PYTHON='python2.7'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "### Below are the paths used by the optional parts of the recipe\n",
      "\n",
      "# We only need the Festival stuff below for the optional text normalization(for LM-training) step\n",
      "#FEST_ROOT=tools/festival\n",
      "#NSW_PATH=${FEST_ROOT}/festival/bin:${FEST_ROOT}/nsw/bin\n",
      "#export PATH=$PATH:$NSW_PATH\n",
      "\n",
      "# SRILM is needed for LM model building\n",
      "#SRILM_ROOT=$KALDI_ROOT/tools/srilm\n",
      "#SRILM_PATH=$SRILM_ROOT/bin:$SRILM_ROOT/bin/i686-m64\n",
      "#export PATH=$PATH:$SRILM_PATH\n",
      "\n",
      "# Sequitur G2P executable\n",
      "#sequitur=$KALDI_ROOT/tools/sequitur/g2p.py\n",
      "#sequitur_path=\"$(dirname $sequitur)/lib/$PYTHON/site-packages\"\n",
      "\n",
      "# Directory under which the LM training corpus should be extracted\n",
      "#LM_CORPUS_ROOT=./lm-corpus\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat path.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 2: ali-to-phones: command not found\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# for any C++ function in `kaldi`, you can call just the function to get information about arguments\n",
    "ali-to-phones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use this function, we also need an acoustic model (again, something we haven't built yet in our pipeline).  A model is provided in `resource_files/feature_viz/model_for_alignments.mdl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 3: ali-to-phones: command not found\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# using ark,t:- we are telling the function to output to STDOUT\n",
    "ali-to-phones \\\n",
    "    resource_files/feature_viz/model_for_alignments.mdl \\\n",
    "    ark:resource_files/feature_viz/all_ali \\\n",
    "    ark,t:- | grep \"1272-128104-0000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generates a sequence of indexes representing the sequence of phones for the given utterance.  If we want to see the actual phones these indexes refer to, we need to `pipe` this output to `int2sym.pl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 1: int2sym.pl: command not found\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "int2sym.pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that this method requires a `symtab` (symbol table), which we have already built in `data/lang/phones.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<eps> 0\n",
      "SIL 1\n",
      "SIL_B 2\n",
      "SIL_E 3\n",
      "SIL_I 4\n",
      "SIL_S 5\n",
      "AA0_B 6\n",
      "AA0_E 7\n",
      "AA0_I 8\n",
      "AA0_S 9\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head data/lang/phones.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 2: ali-to-phones: command not found\n",
      "bash: line 5: int2sym.pl: command not found\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ali-to-phones \\\n",
    "    resource_files/feature_viz/model_for_alignments.mdl \\\n",
    "    ark:resource_files/feature_viz/all_ali \\\n",
    "    ark,t:- |\\\n",
    "    int2sym.pl -f 2- data/lang/phones.txt |\\\n",
    "    grep \"1272-128104-0000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you'll notice that this is waaaaay less sounds than the 584 that we know exist for this audio sample.  In this case, the function collapsed a consecutive sequence of the same phone for easy \"viewing\".  This shouldn't be surprising that a particular sound might last for longer than one frame (which is `25 ms` in our case).\n",
    "\n",
    "We can add the `--per-frame` argument to get a `phone` for each `frame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 2: ali-to-phones: command not found\n",
      "bash: line 6: int2sym.pl: command not found\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ali-to-phones \\\n",
    "    --per-frame=true \\\n",
    "    resource_files/feature_viz/model_for_alignments.mdl \\\n",
    "    ark:resource_files/feature_viz/all_ali \\\n",
    "    ark,t:- |\\\n",
    "    int2sym.pl -f 2- data/lang/phones.txt |\\\n",
    "    grep \"1272-128104-0000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And so now we have a full command we can run that will generate this output for each audio sample in our training set.  We will run it below and save it to `resource_files/feature_viz/all_ali_phoned`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 2: ali-to-phones: command not found\n",
      "bash: line 6: int2sym.pl: command not found\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ali-to-phones \\\n",
    "    --per-frame=true \\\n",
    "    resource_files/feature_viz/model_for_alignments.mdl \\\n",
    "    ark:resource_files/feature_viz/all_ali \\\n",
    "    ark,t:- |\\\n",
    "    int2sym.pl -f 2- data/lang/phones.txt > resource_files/feature_viz/all_ali_phoned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat resource_files/feature_viz/all_ali_phoned | grep \"1272-128104-0000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`feature_viz.py` also has a method for reading in these alignments into a `<dict>`.  And the `value` will be a `<list>` of phones equal to the number of frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'1272-128104-0000'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-4b9eea052d87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mali_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_in_alignments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resource_files/feature_viz/all_ali_phoned\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mali_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSAMPLE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m68\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: '1272-128104-0000'"
     ]
    }
   ],
   "source": [
    "ali_in = fv.read_in_alignments(\"resource_files/feature_viz/all_ali_phoned\")\n",
    "ali_in[SAMPLE][60:68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ali_in[SAMPLE]) == fv.get_num_frames(feats_in[SAMPLE])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can provide the relevant `<list>` of phones to `plot_frames()` to label each frame with its *predicted* phone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.iplot(\n",
    "    fv.plot_frames(\n",
    "        frames=feats_in[SAMPLE][60:68],\n",
    "        phones=ali_in[SAMPLE][60:68]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that these 8 frames *most likely* represent *three* different phones.  \n",
    "\n",
    "Again, clicking on individual lines in the legend will turn that line \"on\"/\"off\" from the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including \"average\" `mfcc` information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`feature_viz.py` also has a function that will calculate the *average* `MFCC` vector for each `phone` in our training subset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to build a `<dict>` that groups all of the `MFCC` vectors for each phone together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dict = fv.get_grouped_phones_dict(\n",
    "                    feats_dict=feats_in, \n",
    "                    ali_dict=ali_in\n",
    ")\n",
    "list(grouped_dict.keys())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each `value` is a `<list>` of all the examples of that phone in our subset.  In this case, there are 5955 *predicteed* `F_B` phones in our subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(grouped_dict[\"F_B\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then run `get_average_mfccs()` to generate the `mean` `MFCC` vector for each phone.  Below is the `mean` `MFCC` vector for all of the `F_B`s seen in our subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_dict = fv.get_average_mfccs(\n",
    "    phones_dict=grouped_dict\n",
    ")\n",
    "ave_dict[\"F_B\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`plot_frames()` can also show you the average vector of each frame that appears in your plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.iplot(\n",
    "    fv.plot_frames(\n",
    "        frames=feats_in[SAMPLE][60:68],\n",
    "        phones=ali_in[SAMPLE][60:68],\n",
    "        average_mfccs_dict=ave_dict\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now compare the particular `MFCC` vectors for a given phone to its average vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study of `IH`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are *five* instances of `IH` in our chosen sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat raw_data/librispeech-transcripts.txt | grep -E \"1272-128104-0000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the frames that correspond to them.\n",
    "\n",
    "**Note:** The phone is `IH1` which indicates the \"second\" pronunciation of `IH` in our phones set.  There is also a `IH0` and a `IH2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat data/lang/phones.txt | grep IH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enumerated_phones = list(enumerate(ali_in[SAMPLE]))\n",
    "\n",
    "list(filter(\n",
    "    lambda x: \"IH\" in x[1],\n",
    "    enumerated_phones)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can see that those *five* instances correspond to the following frames:\n",
    "    - 59-63\n",
    "    - 96-98\n",
    "    - 125-134\n",
    "    - 242-244\n",
    "    - 469-476"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_1 = {\n",
    "    \"start\": 59,\n",
    "    \"stop\": 64    # +1 to be inclusive\n",
    "}\n",
    "\n",
    "ex_2 = {\n",
    "    \"start\": 96,\n",
    "    \"stop\": 99    # +1 to be inclusive\n",
    "}\n",
    "\n",
    "ex_3 = {\n",
    "    \"start\": 125,\n",
    "    \"stop\": 135    # +1 to be inclusive\n",
    "}\n",
    "\n",
    "ex_4 = {\n",
    "    \"start\": 242,\n",
    "    \"stop\": 245    # +1 to be inclusive\n",
    "}\n",
    "\n",
    "ex_5 = {\n",
    "    \"start\": 469,\n",
    "    \"stop\": 477    # +1 to be inclusive\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ali_in[SAMPLE][ex_1[\"start\"]:ex_1[\"stop\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot each sequence of phones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ex_1`: \"MISTER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.iplot(\n",
    "    fv.plot_frames(\n",
    "        frames=feats_in[SAMPLE][ex_1[\"start\"]:ex_1[\"stop\"]],\n",
    "        phones=ali_in[SAMPLE][ex_1[\"start\"]:ex_1[\"stop\"]],\n",
    "        average_mfccs_dict=ave_dict\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ex_2`: \"QUILTER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.iplot(\n",
    "    fv.plot_frames(\n",
    "        frames=feats_in[SAMPLE][ex_2[\"start\"]:ex_2[\"stop\"]],\n",
    "        phones=ali_in[SAMPLE][ex_2[\"start\"]:ex_2[\"stop\"]],\n",
    "        average_mfccs_dict=ave_dict\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ex_3`: \"IS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.iplot(\n",
    "    fv.plot_frames(\n",
    "        frames=feats_in[SAMPLE][ex_3[\"start\"]:ex_3[\"stop\"]],\n",
    "        phones=ali_in[SAMPLE][ex_3[\"start\"]:ex_3[\"stop\"]],\n",
    "        average_mfccs_dict=ave_dict\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ex_4`: \"MIDDLE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.iplot(\n",
    "    fv.plot_frames(\n",
    "        frames=feats_in[SAMPLE][ex_4[\"start\"]:ex_4[\"stop\"]],\n",
    "        phones=ali_in[SAMPLE][ex_4[\"start\"]:ex_4[\"stop\"]],\n",
    "        average_mfccs_dict=ave_dict\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ex_5`: \"HIS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.iplot(\n",
    "    fv.plot_frames(\n",
    "        frames=feats_in[SAMPLE][ex_5[\"start\"]:ex_5[\"stop\"]],\n",
    "        phones=ali_in[SAMPLE][ex_5[\"start\"]:ex_5[\"stop\"]],\n",
    "        average_mfccs_dict=ave_dict\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ex_3` and `ex_5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `ex_3` and `ex_5` are \"IS\" and \"HIS\", respectively, let's plot them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_3_5_frames = np.vstack(\n",
    "    (\n",
    "        feats_in[SAMPLE][ex_3[\"start\"]:ex_3[\"stop\"]],\n",
    "        feats_in[SAMPLE][ex_5[\"start\"]:ex_5[\"stop\"]]\n",
    "    )\n",
    ")\n",
    "ex_3_5_frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_3_5_phones = ali_in[SAMPLE][ex_3[\"start\"]:ex_3[\"stop\"]] + ali_in[SAMPLE][ex_5[\"start\"]:ex_5[\"stop\"]]\n",
    "ex_3_5_phones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.iplot(\n",
    "    fv.plot_frames(\n",
    "        frames=ex_3_5_frames,\n",
    "        phones=ex_3_5_phones,\n",
    "        average_mfccs_dict=ave_dict\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to see any similarity in the individual frames of each `IH`, but we *can* see that the average phone for `IH_B` (when `IH` comes at the **beginning** of a word) and the average phone for `IH_I` (when `IH` comes in the **middle** of a word) are quite similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But then the question remains why these individual frames of a particular `IH` differ so much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### phones in context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these sequence of `IH` phones comes in a different \"context\" (in terms of which phone came before and after them).  And this has a direct effect on the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ex_1` (\"MIS..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's re-plot `ex_1` (\"MISTER\"), but this time with a few frames before and after added for context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.iplot(\n",
    "    fv.plot_frames(\n",
    "        frames=feats_in[SAMPLE][ex_1[\"start\"]-2:ex_1[\"stop\"]+2],\n",
    "        phones=ali_in[SAMPLE][ex_1[\"start\"]-2:ex_1[\"stop\"]+2],\n",
    "        average_mfccs_dict=ave_dict\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare frame `3/9` with `4/9` (the first two frames of `IH`).  They are very similar.\n",
    "\n",
    "Now compare `3/9` to `7/9` (the *first* and *last* frames of `IH`).  Very different.\n",
    "\n",
    "Now compare `2/9` to `3/9` (the *last* `M` frame with the first `IH` frame).  And compare `7/9` with `8/9` (the *last* `IH` frame and the *first* `S` frame)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `ex_2` (\"...WIL...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this sequence (`ex_1`) with `ex_2` (\"QUILTER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py.iplot(\n",
    "    fv.plot_frames(\n",
    "        frames=feats_in[SAMPLE][ex_2[\"start\"]-2:ex_2[\"stop\"]+2],\n",
    "        phones=ali_in[SAMPLE][ex_2[\"start\"]-2:ex_2[\"stop\"]+2],\n",
    "        average_mfccs_dict=ave_dict\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how much \"tighter\" all these frames line up with each other."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
